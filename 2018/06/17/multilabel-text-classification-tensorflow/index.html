<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-label Text Classification with Tensorflow &mdash; Vict0rsch</title>
    
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    
    <link href="https://fonts.googleapis.com/css?family=Nunito:400,700" rel="stylesheet" type="text/css">
    <!-- <link rel="stylesheet" href="/assets/main.css"> -->

    <link rel="stylesheet" type="text/css" href="/assets/main-52ae7e3dfe5a5913b1a1f11b64d5f74b05fbe724da7d42f261065884084029ab.css" integrity="sha256-Uq5+Pf5aWROxofEbZNX3SwX75yTafULyYQZYhAhAKas=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/assets/tingle-141cb380cbc51d7fad4249751d1e3cffb07ccff80f6b0836164a30c2b857bf2a.css" integrity="sha256-FByzgMvFHX+tQkl1HR48/7B8z/gPawg2FkowwrhXvyo=" crossorigin="anonymous">
    <!-- <link rel="stylesheet" href="/assets/tingle.css"> -->

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="/images/light-bulb.svg" />
    <!--rss-feed <link href="/feed.xml" rel="alternate" type="application/rss+xml" title="Vict0rsch" /> -->
    <meta name="title" content="Multi-label Text Classification with Tensorflow ">
    <link rel="canonical" href="https://vict0rs.ch/2018/06/17/multilabel-text-classification-tensorflow/">
    
    
    <meta property="og:title" content="Multi-label Text Classification with Tensorflow " />
    <meta property="og:url" content="https://vict0rs.ch/2018/06/17/multilabel-text-classification-tensorflow/" />
    
    
    <meta property="og:description" content="Multilabel classification requires some changes to the mainstream single-label case: here they are!" />
    <meta name="description" content="Multilabel classification requires some changes to the mainstream single-label case: here they are!" />
    
    <meta property="og:site_name" content="Vict0rsch">
    
    <!--google analytics tracking code here-->
<script>
 (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
 (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
 m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
 })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

 ga('create', 'UA-88678459-1', 'auto');
 ga('send', 'pageview');
 
 console.log('gogol analytics')
</script>

    
    <script src="https://unpkg.com/nprogress@0.2.0/nprogress.js"></script>
<style>
#nprogress{pointer-events:none}#nprogress .bar{background:#2077b2;position:fixed;z-index:1031;top:0;left:0;width:100%;height:3px}#nprogress .peg{display:block;position:absolute;right:0;width:100px;height:100%;box-shadow:0 0 10px #2077b2,0 0 5px #2077b2;opacity:1;-webkit-transform:rotate(3deg) translate(0px,-4px);-ms-transform:rotate(3deg) translate(0px,-4px);transform:rotate(3deg) translate(0px,-4px)}#nprogress .spinner{display:block;position:fixed;z-index:1031;top:15px;right:15px}#nprogress .spinner-icon{width:18px;height:18px;box-sizing:border-box;border:solid 2px transparent;border-top-color:#2077b2;border-left-color:#2077b2;border-radius:50%;-webkit-animation:nprogress-spinner 400ms linear infinite;animation:nprogress-spinner 400ms linear infinite}.nprogress-custom-parent{overflow:hidden;position:relative}.nprogress-custom-parent #nprogress .spinner,.nprogress-custom-parent #nprogress .bar{position:absolute}@-webkit-keyframes nprogress-spinner{0%{-webkit-transform:rotate(0deg)}100%{-webkit-transform:rotate(360deg)}}@keyframes nprogress-spinner{0%{transform:rotate(0deg)}100%{transform:rotate(360deg)}}
</style>

</head>

<body>
    <script>
        NProgress.configure({
            easing: 'ease',
            speed: 600,
            showSpinner: false,
        });
        NProgress.start();
        var int = setInterval(()=> {
            NProgress.inc()
        }, 500)
        window.onload = function(){
            clearInterval(int);
            NProgress.done();
        };
    </script>

    <div id='wrapper'>
        <div id='main'>
            <section id="navbar" class="site-nav">
                <header>
                    <nav id="navigation">
                        <a class="brand" href="/">
                            <img src="/images/light-bulb.svg" alt="Home"><span class="hidable-nav">Home</span>
                        </a>
                        
                        <a href="/resources">Resources</a>
                        
                        <a href="/about">About</a>
                        
                        
                        <a href="#" class='search-link'>
                                <span class="hidable-nav">Search</span> <i class="fa fa-search"></i>
                        </a>
                        
                    </nav>
                    <nav class="tagline">
                        <span>Learn Keras and Lasagne (2015)</span>
                        <a href="/tutorials" class="btn btn-outline">Tutorials</a>
                    </nav>
                </header>
            </section>

            
<article>
    <div class="container">
        <header>
            
            <div class="meta">
                <span class='meta_text'>By</span> <address><a rel="author" href="" title="Victor Schmidt"
                        target="_blank">Victor Schmidt</a></address> <span class='meta_text'>&mdash;
                    <time pubdate datetime="2018-17-June" title="June 17, 2018">June 17, 2018</time></span>
            </div>
            
            <h1 class="title">Multi-label Text Classification with Tensorflow</h1><span id='title_buttons'><a id='night_mode' class="btn btn-outline dark">Read
                    in the dark</a></span>
            
        </header>

        <section>
            <div id='post-content'>
                <p>Which loss should you use? How to use the <code class="language-plaintext highlighter-rouge">tf.data.Dataset</code> API with a train and a validation set? How to use streaming metrics? Here are my answers.</p>

<p>This post is about the specifics of the multilabel setting, and a little about how to handle sequences of sequences. It is not about an NLP pipeline nor is it about the model you should use. The overall idea is aimed at using the <code class="language-plaintext highlighter-rouge">Dataset</code> API and about a few gotchas to pay attention to when handling multilabel data. Check out the table of contents for more details.</p>

<p>A lot of the content here comes from</p>

<ul>
  <li><a href="https://cs230-stanford.github.io/tensorflow-input-data.html">Stanford’s CS 230</a></li>
  <li><a href="http://vict0rsch.github.io/2018/05/24/sample-multilabel-dataset/">Sampling Multilabel Datasets</a></li>
  <li><a href="http://vict0rsch.github.io/2018/06/06/tensorflow-streaming-multilabel-f1/">Streaming f1-score in a multilabel setting</a></li>
</ul>

<p>Feel free to comment on what’s written here: typos, suggestions, other changes I’ve missed or errors I’ve made! Also, some things may not be optimal, I’m open to improvements to my solutions!</p>

<p><br /></p>

<ol id="markdown-toc">
  <li><a href="#data" id="markdown-toc-data">Data</a>    <ol>
      <li><a href="#preparing-the-dataset" id="markdown-toc-preparing-the-dataset">Preparing the dataset</a>        <ol>
          <li><a href="#train-validation-test-sampling" id="markdown-toc-train-validation-test-sampling">Train, Validation, Test: Sampling</a></li>
          <li><a href="#text-sequences-of-sequences" id="markdown-toc-text-sequences-of-sequences">Text: sequences of sequences</a></li>
          <li><a href="#vocabulary" id="markdown-toc-vocabulary">Vocabulary</a></li>
          <li><a href="#labels" id="markdown-toc-labels">Labels</a></li>
        </ol>
      </li>
      <li><a href="#loading-the-data-with-tfdatadataset" id="markdown-toc-loading-the-data-with-tfdatadataset">Loading the data with <code class="language-plaintext highlighter-rouge">tf.data.Dataset</code></a>        <ol>
          <li><a href="#feeding-sequences-of-sequences-inside-a-tensorflow-dataset" id="markdown-toc-feeding-sequences-of-sequences-inside-a-tensorflow-dataset">Feeding sequences of sequences inside a Tensorflow Dataset</a></li>
          <li><a href="#processing-the-labels" id="markdown-toc-processing-the-labels">Processing the labels</a></li>
          <li><a href="#creating-a-dataset-and-input-tensors" id="markdown-toc-creating-a-dataset-and-input-tensors">Creating a <code class="language-plaintext highlighter-rouge">Dataset</code> and input Tensors</a></li>
          <li><a href="#handling-the-validation-data" id="markdown-toc-handling-the-validation-data">Handling the validation data</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#model" id="markdown-toc-model">Model</a>    <ol>
      <li><a href="#loss" id="markdown-toc-loss">Loss</a></li>
      <li><a href="#prediction" id="markdown-toc-prediction">Prediction</a></li>
      <li><a href="#metrics" id="markdown-toc-metrics">Metrics</a></li>
      <li><a href="#training" id="markdown-toc-training">Training</a></li>
    </ol>
  </li>
</ol>

<h1 id="data">Data</h1>

<h2 id="preparing-the-dataset">Preparing the dataset</h2>

<h3 id="train-validation-test-sampling">Train, Validation, Test: Sampling</h3>

<p>In the <em>single-label</em> situation, the usual and easy way to keep the datasets’ statistics equal is to sample independently each class of the original dataset. It’s a valid procedure in this case: if you want 70% of your data in the train set, you take 70% of samples with class <em>A</em>, 70% of samples with class <em>B</em> and so on.</p>

<p>How would you do that if each sample can be of multiple classes simultaneously? The single-label procedure is only valid as long as you can sample <strong>independantly</strong> each class, which is no longer possible!</p>

<p>Check out my <a href="http://vict0rsch.github.io/2018/05/24/sample-multilabel-dataset/">blog post on sampling multilabel datasets</a> to appropriately do so.</p>

<h3 id="text-sequences-of-sequences">Text: sequences of sequences</h3>

<p>You obviously need to prepare tour text according to standard nlp pipelines. As we’ll use the <code class="language-plaintext highlighter-rouge">tf.data.Dataset</code> API, we’ll simply write our texts to a text file, one text to be classified per line. Something like:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">processed_texts</span> <span class="o">=</span> <span class="n">my_nlp_pipeline</span><span class="p">()</span>  <span class="c1"># processed_texts = ['this is a text', 'this is another text to classify', ...]
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'data.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">processed_texts</span><span class="p">))</span></code></pre></figure>

<p>My work involves working with 2-level sequences: the Hierarchical Attention Network requires the data to be processed as documents wich are lists of sentences which are lists of words. If you don’t need this hierarchical structure, do move forward. If you need it, my solution is to still write one document per line, but separate sentences with a fixed token.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">hierarchical_processed_texts</span> <span class="o">=</span> <span class="n">my_nlp_pipeline</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'data.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span>
        <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span>
            <span class="s">'|&amp;|'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">hierarchical_processed_texts</span>
        <span class="p">)</span>
    <span class="p">)</span></code></pre></figure>

<p>For instance, we’d write such a text file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This is a comment from the yelp dataset .|&amp;|It reprensents a document .|&amp;|Its sentences are separated by a token .
This is another comment .|&amp;|It says that John's pizzas are great .|&amp;|The author would go back .|&amp;|Nice staff .
...
</code></pre></div></div>

<p>This will allow us to split documents on <code class="language-plaintext highlighter-rouge">|&amp;|</code> and then sentences on whitespaces <code class="language-plaintext highlighter-rouge">_</code>.</p>

<h3 id="vocabulary">Vocabulary</h3>

<p>In any case we need to write a text file with the vocabulary. Each line should contain a word and the line’s number will be the word’s index in the vocabulary.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="n">pad_token</span> <span class="o">=</span> <span class="s">"&lt;pad&gt;"</span>

<span class="n">processed_texts</span> <span class="o">=</span> <span class="n">my_nlp_pipeline</span><span class="p">()</span>

<span class="n">all_vocab</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">processed_texts</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">):</span>
        <span class="n">all_vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">ordered_vocab</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">all_vocab</span><span class="p">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">all_vocab</span><span class="p">.</span><span class="n">get</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># most frequent words first
</span><span class="n">ordered_vocab</span> <span class="o">=</span> <span class="p">[</span><span class="n">pad_token</span><span class="p">]</span> <span class="o">+</span> <span class="n">ordered_vocab</span>  <span class="c1"># you want the padding token to have index 0
</span>
<span class="n">max_vocab_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">)</span>  <span class="c1"># you may not want all possible words
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'./words.txt'</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">ordered_vocab</span><span class="p">[:</span><span class="n">max_vocab_size</span><span class="p">]))</span></code></pre></figure>

<h3 id="labels">Labels</h3>

<p>Again, we’ll write labels in a text file:</p>

<ul>
  <li>Find all possible labels</li>
  <li>Assign them an index</li>
  <li>One-hot encode lists of labels</li>
  <li>Write to text file.</li>
</ul>

<p>For instance say you have 4 classes, up to 3 labels and 5 samples:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">samples</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">[</span><span class="s">"Culture"</span><span class="p">,</span> <span class="s">"War"</span><span class="p">]</span>
  <span class="p">[</span><span class="s">"War"</span><span class="p">,</span> <span class="s">"Philosophy"</span><span class="p">,</span> <span class="s">"Love"</span><span class="p">]</span>
  <span class="p">[</span><span class="s">"Love"</span><span class="p">,</span> <span class="s">"Culture"</span><span class="p">]</span>
  <span class="p">[</span><span class="s">"War"</span><span class="p">]</span>
  <span class="p">[</span><span class="s">"Culture"</span><span class="p">,</span> <span class="s">"Love"</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">all_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">label</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">)</span>
<span class="n">ordered_labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">all_labels</span><span class="p">)</span>
<span class="n">labels_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">l</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ordered_labels</span><span class="p">)}</span>

<span class="n">one_hot_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_labels</span><span class="p">))).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
        <span class="n">one_hot_labels</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">labels_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">np</span><span class="p">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">one_hot_samples</span><span class="p">,</span> <span class="s">'./one_hot_labels.txt'</span><span class="p">)</span></code></pre></figure>

<p>one_hot_labels.txt:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1, 0, 0, 1
0, 1, 1, 1
1, 1, 0, 0
0, 0, 0, 1
1, 1, 0, 0
</code></pre></div></div>

<h2 id="loading-the-data-with-tfdatadataset">Loading the data with <code class="language-plaintext highlighter-rouge">tf.data.Dataset</code></h2>

<h3 id="feeding-sequences-of-sequences-inside-a-tensorflow-dataset">Feeding sequences of sequences inside a Tensorflow Dataset</h3>

<p>In the regular situation, all we have to do is split texts into words. In the hierarchical situation, we also need to split sentences:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">extract_sents</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="c1"># Split the document line into sentences
</span>    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">string_split</span><span class="p">([</span><span class="n">doc</span><span class="p">],</span> <span class="s">'|&amp;|'</span><span class="p">).</span><span class="n">values</span>

<span class="k">def</span> <span class="nf">extract_words</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="c1"># Split characters
</span>    <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">string_split</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">" "</span><span class="p">)</span>
    <span class="c1"># Convert to Dense tensor, filling with default value
</span>    <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">sparse_tensor_to_dense</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="n">pad_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>


<span class="n">num_threads</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">lookup</span><span class="p">.</span><span class="n">index_table_from_file</span><span class="p">(</span><span class="n">your_vocabulary_file</span><span class="p">,</span> <span class="n">num_oov_buckets</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">texts_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">TextLineDataset</span><span class="p">(</span><span class="n">your_texts_file</span><span class="p">)</span>

<span class="n">texts_dataset</span> <span class="o">=</span> <span class="n">texts_dataset</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">extract_sents</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">)</span>
<span class="n">texts_dataset</span> <span class="o">=</span> <span class="n">texts_dataset</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">extract_words</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">)</span>
<span class="n">texts_dataset</span> <span class="o">=</span> <span class="n">texts_dataset</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">.</span><span class="n">lookup</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">)</span></code></pre></figure>

<h3 id="processing-the-labels">Processing the labels</h3>

<p>We need to read the one-hot encoded text file and turn it into tensors:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">one_hot_multi_label</span><span class="p">(</span><span class="n">string_one_hot</span><span class="p">):</span>
    <span class="c1"># split on ", " and get dense Tensor
</span>    <span class="n">vals</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">string_split</span><span class="p">([</span><span class="n">string_one_hot</span><span class="p">],</span> <span class="n">split_label_token</span><span class="p">).</span><span class="n">values</span>
    <span class="c1"># convert to numbers
</span>    <span class="n">numbs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">string_to_number</span><span class="p">(</span><span class="n">vals</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">numbs</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">labels_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">TextLineDataset</span><span class="p">(</span><span class="n">your_texts_file</span><span class="p">)</span>
<span class="n">labels_dataset</span> <span class="o">=</span> <span class="n">labels_dataset</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">one_hot_multi_label</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">)</span></code></pre></figure>

<h3 id="creating-a-dataset-and-input-tensors">Creating a <code class="language-plaintext highlighter-rouge">Dataset</code> and input Tensors</h3>

<p>Now we need to zip the labels and texts datasets together so that we can shuffle them together, batch and prefetch them:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>  <span class="c1"># could be a placeholder
</span>
<span class="n">padded_shapes</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="bp">None</span><span class="p">]),</span>
<span class="p">)</span> 

<span class="n">padding_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">int32</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="c1"># 0 is the index of our &lt;pad&gt; token
# for some reason running the same code on linux or macOS raises type erros. Adjust the type
# of your 0 padding_values according to your platform
</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nb">zip</span><span class="p">((</span><span class="n">texts_dataset</span><span class="p">,</span> <span class="n">labels_dataset</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">reshuffle_each_iteration</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">padded_shapes</span><span class="p">,</span> <span class="n">padding_values</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">iterator</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Iterator</span><span class="p">.</span><span class="n">from_structure</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">.</span><span class="n">output_types</span><span class="p">,</span>
    <span class="n">dataset</span><span class="p">.</span><span class="n">output_shapes</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">dataset_init_op</span> <span class="o">=</span> <span class="n">iterator</span><span class="p">.</span><span class="n">make_initializer</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"dataset_init_op"</span>
<span class="p">)</span>

<span class="n">input_tensor</span><span class="p">,</span> <span class="n">labels_tensor</span> <span class="o">=</span> <span class="n">iterator</span><span class="p">.</span><span class="n">get_next</span><span class="p">()</span></code></pre></figure>

<p>Repeating for several epochs will be done manually at run time for more flexibility.</p>

<details><summary>Wondering about <code class="language-plaintext highlighter-rouge">padded_shapes</code>? (click to expand)</summary><div class="detailsContent">
<p><code class="language-plaintext highlighter-rouge">padded_shapes</code> is a tuple. The first <code class="language-plaintext highlighter-rouge">shape</code> will be used to pad the features (<em>i.e.</em> the 3D Tensor with the list of word indexes for each sentence in each document), and the second is for the labels.</p>

<p>The <strong>labels</strong> won’t require padding as they are already a consistent 2D array in the text file which will be converted to a 2D Tensor. But Tensorflow does not know it won’t need to pad the labels, so we still need to specify the <code class="language-plaintext highlighter-rouge">padded_shape</code> argument: if need be, the Dataset should pad each sample with a 1D Tensor (hence <code class="language-plaintext highlighter-rouge">tf.TensorShape([None])</code>). For instance if a label was <code class="language-plaintext highlighter-rouge">[0, 1, 0, 0, 1]</code> and the next one was <code class="language-plaintext highlighter-rouge">[0, 1]</code> then the padding would be <code class="language-plaintext highlighter-rouge">[0, 0, 0]</code> as we said that the <code class="language-plaintext highlighter-rouge">padding_value</code> should be <code class="language-plaintext highlighter-rouge">0</code>.</p>

<p>The <strong>features</strong> on the other hand will need padding as within a batch (a list of documents, first dimension of the 3D batch Tensor), all documents won’t have the same number of sentences (2nd dimension of the Tensor) and all sentences within the batch won’t have the same number of words (last dimension). The Dataset may therefore need to patch 2 dimensions (sentences and words), hence <code class="language-plaintext highlighter-rouge">tf.TensorShape([None, None])</code>. And as we put the padding token first in the vocabulary, then its index is 0 and the <code class="language-plaintext highlighter-rouge">padding_value</code> is also 0.</p>

<p>Lastly, we need the types of <code class="language-plaintext highlighter-rouge">padding_values</code> to be consistent with the types of the <code class="language-plaintext highlighter-rouge">features</code> and <code class="language-plaintext highlighter-rouge">labels</code> tensors produced by the <code class="language-plaintext highlighter-rouge">text_dataset</code> and the <code class="language-plaintext highlighter-rouge">labels_dataset</code>, which is why I used <code class="language-plaintext highlighter-rouge">np.int*</code>.</p>

</div></details>

<h3 id="handling-the-validation-data">Handling the validation data</h3>

<p>Actually what you should do is have a dataset for your training data and another one for your validation data. This will allow you to use one without affecting the other. People usually use only one dataset and re-initialize it with validation data at the end of each epoch. I like having 2 datasets because I don’t want to wait for the end of an epoch to validate.</p>

<p>To do so, just do the previous procedure inside a <code class="language-plaintext highlighter-rouge">with tf.variable_scope(train_or_val):</code> and use <code class="language-plaintext highlighter-rouge">tf.cond</code> to chose the dataset:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">is_training</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"train-dataset"</span><span class="p">):</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="p">...</span>
    <span class="p">...</span>
    <span class="n">train_iter</span> <span class="o">=</span> <span class="p">...</span>
    <span class="n">train_dataset_init_op</span> <span class="o">=</span> <span class="p">...</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"val-dataset"</span><span class="p">):</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="p">...</span>
    <span class="p">...</span>
    <span class="n">val_iter</span> <span class="o">=</span> <span class="p">...</span>
    <span class="n">val_dataset_init_op</span> <span class="o">=</span> <span class="p">...</span>

<span class="n">input_tensor</span><span class="p">,</span> <span class="n">labels_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cond</span><span class="p">(</span><span class="n">is_training</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">.</span><span class="n">get_next</span><span class="p">,</span> <span class="n">val_iter</span><span class="p">.</span><span class="n">get_next</span><span class="p">)</span></code></pre></figure>

<h1 id="model">Model</h1>

<h2 id="loss">Loss</h2>

<p>We want each dimension of our model’s logits to be an independant logistic regression. We’ll therefore use <code class="language-plaintext highlighter-rouge">tf.nn.sigmoid_cross_entropy_with_logits</code>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">logits</span> <span class="o">=</span> <span class="n">your_model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_tensor</span><span class="p">)</span>
<span class="c1"># loss has the same shape as logits: 1 loss per class and per sample in the batch
</span><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span></code></pre></figure>

<p>Notice how the loss is summed accross classes before it is averaged over the batch. I’m not 100% positive, if you have an opinion, do checkout the <a href="https://github.com/tensorflow/skflow/issues/113">discussion on github here</a>.</p>

<h2 id="prediction">Prediction</h2>

<p>Unlike the single-label case, we should not output a softmax probability distribultion as labels are classified independently. We need just apply a <code class="language-plaintext highlighter-rouge">sigmoid</code> on the logits as they are independant logistic regressions:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">multi_label_hot</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">greater</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">threshold</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>

<span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
<span class="n">one_hot_prediction</span> <span class="o">=</span> <span class="n">multi_label_hot</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span></code></pre></figure>

<h2 id="metrics">Metrics</h2>

<p>I highly recommend you <a href="https://stackoverflow.com/a/46414395/3867406">learn about streaming metrics</a>. Also, checkout my <a href="http://vict0rsch.github.io/2018/06/06/tensorflow-streaming-multilabel-f1/">previous blogpost about streaming f1-score</a> in the multilabel setting to understand <code class="language-plaintext highlighter-rouge">streaming_f1</code>. Here is a function meant to gather training and validation metrics:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_metrics</span><span class="p">(</span><span class="n">labels_tensor</span><span class="p">,</span> <span class="n">one_hot_prediction</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"metrics"</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">scope</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"train"</span><span class="p">,</span> <span class="s">"val"</span><span class="p">]:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"f1"</span><span class="p">):</span>
                    <span class="n">f1s</span><span class="p">,</span> <span class="n">f1_updates</span> <span class="o">=</span> <span class="n">streaming_f1</span><span class="p">(</span>
                        <span class="n">labels_tensor</span><span class="p">,</span>
                        <span class="n">one_hot_prediction</span><span class="p">,</span>
                        <span class="n">num_classes</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">micro_f1</span><span class="p">,</span> <span class="n">macro_f1</span><span class="p">,</span> <span class="n">weighted_f1</span> <span class="o">=</span> <span class="n">f1s</span>
                <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"accuracy"</span><span class="p">):</span>
                    <span class="n">accuracy</span><span class="p">,</span> <span class="n">accuracy_update</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span>
                        <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">one_hot_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">),</span>
                        <span class="n">labels_tensor</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">metrics</span><span class="p">[</span><span class="n">scope</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">"accuracy"</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
                    <span class="s">"f1"</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s">"micro"</span><span class="p">:</span> <span class="n">micro_f1</span><span class="p">,</span>
                        <span class="s">"macro"</span><span class="p">:</span> <span class="n">macro_f1</span><span class="p">,</span>
                        <span class="s">"weighted"</span><span class="p">:</span> <span class="n">weighted_f1</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="s">"updates"</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">group</span><span class="p">(</span><span class="n">f1_updates</span><span class="p">,</span> <span class="n">accuracy_update</span><span class="p">),</span>
                <span class="p">}</span>
    <span class="k">return</span> <span class="n">metrics</span></code></pre></figure>

<h2 id="training">Training</h2>

<p>Here is the skeletton for a training procedure.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">metrics</span> <span class="o">=</span> <span class="n">get_metrics</span><span class="p">(</span><span class="n">labels_tensor</span><span class="p">,</span> <span class="n">one_hot_prediction</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

<span class="n">opt_op</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="c1"># Create your own optimize() function with your preferred
</span>                        <span class="c1"># optimizer, clipped gradients and so on
</span>
<span class="n">train_fd</span> <span class="o">=</span> <span class="p">{</span><span class="n">is_training</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span>
<span class="n">val_fd</span> <span class="o">=</span> <span class="p">{</span><span class="n">is_training</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

    <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">().</span><span class="n">run</span><span class="p">(</span><span class="n">session</span><span class="o">=</span><span class="n">sess</span><span class="p">)</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">tables_initializer</span><span class="p">().</span><span class="n">run</span><span class="p">(</span><span class="n">session</span><span class="o">=</span><span class="n">sess</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_of_epochs</span><span class="p">):</span>

        <span class="n">stop</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_dataset_init_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">train_fd</span><span class="p">)</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="n">stop</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">mic</span><span class="p">,</span> <span class="n">mac</span><span class="p">,</span> <span class="n">wei</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">([</span>
                    <span class="n">loss</span><span class="p">,</span> 
                    <span class="n">global_step</span><span class="p">,</span> <span class="c1"># this variable is usually incremented by optimizer.optimize()
</span>                    <span class="n">opt_op</span><span class="p">,</span>
                    <span class="n">metrics</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"updates"</span><span class="p">],</span>
                    <span class="n">metrics</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"accuracy"</span><span class="p">],</span>
                    <span class="n">metrics</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"f1"</span><span class="p">][</span><span class="s">"micro"</span><span class="p">],</span>
                    <span class="n">metrics</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"f1"</span><span class="p">][</span><span class="s">"macro"</span><span class="p">],</span>
                    <span class="n">metrics</span><span class="p">[</span><span class="s">"train"</span><span class="p">][</span><span class="s">"f1"</span><span class="p">][</span><span class="s">"weighted"</span><span class="p">]</span>
                <span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">train_fd</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">%</span> <span class="n">val_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">val_dataset_init_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">val_fd</span><span class="p">)</span>
                    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">_</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">mic</span><span class="p">,</span> <span class="n">mac</span><span class="p">,</span> <span class="n">wei</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span>
                                <span class="p">[</span>
                                    <span class="n">metrics</span><span class="p">[</span><span class="s">"val"</span><span class="p">][</span><span class="s">"updates"</span><span class="p">],</span>
                                    <span class="n">metrics</span><span class="p">[</span><span class="s">"val"</span><span class="p">][</span><span class="s">"accuracy"</span><span class="p">],</span>
                                    <span class="n">metrics</span><span class="p">[</span><span class="s">"val"</span><span class="p">][</span><span class="s">"f1"</span><span class="p">][</span><span class="s">"micro"</span><span class="p">],</span>
                                    <span class="n">metrics</span><span class="p">[</span><span class="s">"val"</span><span class="p">][</span><span class="s">"f1"</span><span class="p">][</span><span class="s">"macro"</span><span class="p">],</span>
                                    <span class="n">metrics</span><span class="p">[</span><span class="s">"val"</span><span class="p">][</span><span class="s">"f1"</span><span class="p">][</span><span class="s">"weighted"</span><span class="p">]</span>
                                <span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">val_fd</span>
                            <span class="p">)</span>
                        <span class="k">except</span> <span class="n">tf</span><span class="p">.</span><span class="n">errors</span><span class="p">.</span><span class="n">OutOfRangeError</span><span class="p">:</span>
                            <span class="k">break</span>
                    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Validation : '</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">mic</span><span class="p">,</span> <span class="n">mac</span><span class="p">,</span> <span class="n">wei</span><span class="p">)</span>

            <span class="k">except</span> <span class="n">tf</span><span class="p">.</span><span class="n">errors</span><span class="p">.</span><span class="n">OutOfRangeError</span><span class="p">:</span>
                <span class="n">stop</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">'Epoch {:3} step {:5}: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                    <span class="n">epoch</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">loss</span>
                <span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s">"</span><span class="se">\r</span><span class="s">"</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'End of Training'</span><span class="p">)</span></code></pre></figure>


            </div>
            
<div class="social">
    
    <div class='custom_twitter_share'>
        <a href="https://twitter.com/share" class="twitter-share-button"  data-text="Multi-label Text Classification with Tensorflow" data-related="vict0rsch">Tweet</a>
    </div>
    
    
    <div class='custom_fb_share'>
        <div class="fb-like" data-width="150" data-layout="button_count" data-action="like" data-show-faces="true" data-send="false"></div>
    </div>
    
    
    
    
</div>

        </section>

        <footer>
            <address>
                
                <p>
                    Written by <strong><a rel="author" href="https://twitter.com/vict0rsch" title=""
                            target="_blank">Victor Schmidt</a></strong>
                    <span class="muted"></span>
                    
                    &nbsp;- <iframe class='followGithub' src="https://ghbtns.com/github-btn.html?user=vict0rsch&type=follow&count=false&size=small"
                        frameborder="0" scrolling="0" width="220px" height="20px" align="top"></iframe>
                    
                </p>
                
            </address>

        </footer>

        
        <section>
            <!-- <div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-vict0rsch-github-io'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script> -->

        </section>
        
    </div>
</article>
        </div>
    </div>

    <footer class="site-footer" id="footer">
        <div class="container" style="display: flex; align-items: center; justify-content: space-between; margin-bottom: 2.5rem">
            <div id="footer-subcontainer">
                <nav>
                    &copy; 2021
                    <!-- <a href=""></a> &middot; -->
                    <a href="/">Posts</a> &middot;
                    <a class="search-link" href="#">Search</a> &middot;
                    
                    <a href="/resources">Resources</a> &middot;
                    
                    
                    <a href="/about">About</a>
                    <span id="iframe-middot">
                        &middot;
                    </span>

                    
                    <div id="iframe-stars">
                        <iframe src="https://ghbtns.com/github-btn.html?user=vict0rsch&repo=deep_learning&type=star&count=true&size=small"
                            frameborder="0" scrolling="0" width="84px" height="20px" align="top"></iframe>
                    </div>
                </nav>
                <a class="brand" href="/" id="logo-footer">
                    <img src="/images/light-bulb.svg" alt="Home">
                </a>
            </div>
            <nav class="social" style="display: none">
                
                <!--<a href="https://twitter.com/vict0rsch" title="Follow on Twitter" target="_blank"><i class="icon icon-twitter black"></i></a> -->
                
                
                <!--<a href="/feed.xml" title="RSS Feed">
                <i class="icon icon-rss
                black"></i>
            </a> -->
            </nav>
        </div>
        <!-- <p style="text-align: center">Incorporated theme by <a href="https://sendtoinc.com">Inc</a></p> -->
    </footer>

    <script src="https://code.jquery.com/jquery-3.4.0.min.js"
  integrity="sha256-BJeo0qm959uMBGb65z40ejJYGSgR7REI4+CW1fNKwOg=" crossorigin="anonymous"></script>

<script src="https://cdn.jsdelivr.net/npm/typeit@v6/dist/typeit.min.js" />

// <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.0/anchor.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.0/anchor.min.js"></script>


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

<script integrity="sha256-OtUha0k2/9UfGo5Gk1z/sd7U+h+D976k0yB92whsPW4=" crossorigin="anonymous" src="/assets/jquery.details.min-3ad5216b4936ffd51f1a8e46935cffb1ded4fa1f83f7bea4d3207ddb086c3d6e.js" type="text/javascript"></script>
<script integrity="sha256-4wzmvLQ/OBBCfxELN4DUGzj7PW+xnN7NlI0d//TQB18=" crossorigin="anonymous" src="/assets/main-e30ce6bcb43f3810427f110b3780d41b38fb3d6fb19cdecd948d1dfff4d0075f.js" type="text/javascript"></script>
<script integrity="sha256-onGmRDUJ8Zf39A1uJov1b9pZtNzd5TxySBgWLJF0VY4=" crossorigin="anonymous" src="/assets/tingle-a271a6443509f197f7f40d6e268bf56fda59b4dcdde53c724818162c9174558e.js" type="text/javascript"></script>
<script integrity="sha256-CfaxBGUjUvpFlFRKgjFuU0wjm8nOSRE6pEV3OnmjJIc=" crossorigin="anonymous" src="/assets/search-09f6b104652352fa4594544a82316e534c239bc9ce49113aa445773a79a32487.js" type="text/javascript"></script>
<script integrity="sha256-bcehUY3Ujb9kllPCKFSl6b1nP5+Be8VJ9/5tW9wOLyQ=" crossorigin="anonymous" src="/assets/resourceCards-6dc7a1518dd48dbf649653c22854a5e9bd673f9f817bc549f7fe6d5bdc0e2f24.js" type="text/javascript"></script>




<script>!function (d, s, id) { var js, fjs = d.getElementsByTagName(s)[0], p = /^http:/.test(d.location) ? 'http' : 'https'; if (!d.getElementById(id)) { js = d.createElement(s); js.id = id; js.src = p + '://platform.twitter.com/widgets.js'; fjs.parentNode.insertBefore(js, fjs); } }(document, 'script', 'twitter-wjs');</script>



<div id="fb-root"></div>
<script>(function (d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=253595308025739";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));</script>








</body>

</html>
